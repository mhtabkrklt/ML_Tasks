{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOYTsxBLJe3S8YXCyQuTTjS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhtabkrklt/ML_Tasks/blob/main/product_quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ДЗ: Реализовать product quantization самостоятельно и посчитать ошибку представления на 2 датасетах:\n",
        "- сгенерированом так, чтобы в каждом под-пространстве вектора хорошо кластеризовались (центр + белый шум)\n",
        "- эмбеддингах любого датасета от любой нейронки"
      ],
      "metadata": {
        "id": "aT8UkVPguXpO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9w5LEcvl1DY",
        "outputId": "aef6448a-78b4-4fa6-a5e0-6172172c4860"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x781eeb717110>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализация Product Quantizer"
      ],
      "metadata": {
        "id": "be83H7N1sCqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProductQuantizer:\n",
        "    def __init__(self, m: int, nbits: int = 8):\n",
        "        \"\"\"\n",
        "        m: количество подпространств (сегментов)\n",
        "        nbits: количество бит на сегмент (обычно 8 -> 256 кластеров)\n",
        "        \"\"\"\n",
        "        self.m = m\n",
        "        self.k = 2 ** nbits\n",
        "        self.codebooks = None\n",
        "        self.d_s = None # Размерность одного сегмента\n",
        "\n",
        "    def fit(self, x: np.ndarray):\n",
        "        n_samples, d = x.shape\n",
        "        assert d % self.m == 0, f\"Размерность вектора {d} должна делиться на m={self.m}\"\n",
        "        self.d_s = d // self.m\n",
        "\n",
        "        # codebooks: (m, k, d_s) - m книг, в каждой k слов длины d_s\n",
        "        self.codebooks = np.empty((self.m, self.k, self.d_s), dtype=np.float32)\n",
        "\n",
        "        print(f\"Обучение PQ: Вектор {d} dim -> {self.m} сегментов по {self.d_s} dim.\")\n",
        "\n",
        "        # Для каждого подпространства обучаем свой K-Means\n",
        "        for i in tqdm.tqdm(range(self.m), desc=\"Обучение кодовых книг\"):\n",
        "            # Вырезаем i-й сегмент у всех векторов\n",
        "            x_sub = x[:, i * self.d_s : (i + 1) * self.d_s]\n",
        "\n",
        "            # Кластеризуем\n",
        "            kmeans = KMeans(n_clusters=self.k, n_init=5, max_iter=50, random_state=42)\n",
        "            kmeans.fit(x_sub)\n",
        "\n",
        "            # Сохраняем центроиды\n",
        "            self.codebooks[i] = kmeans.cluster_centers_\n",
        "\n",
        "    def encode(self, x: np.ndarray) -> np.ndarray:\n",
        "        n_samples, d = x.shape\n",
        "        codes = np.empty((n_samples, self.m), dtype=np.uint8)\n",
        "\n",
        "        for i in range(self.m):\n",
        "            x_sub = x[:, i * self.d_s : (i + 1) * self.d_s]\n",
        "            codebook = self.codebooks[i]\n",
        "\n",
        "            # Считаем расстояния: (N, 1, d_s) - (1, K, d_s) -> (N, K)\n",
        "            # Используем broadcasting для скорости\n",
        "            dists = np.linalg.norm(x_sub[:, None, :] - codebook[None, :, :], axis=2)\n",
        "\n",
        "            # Индекс ближайшего центроида\n",
        "            codes[:, i] = np.argmin(dists, axis=1)\n",
        "\n",
        "        return codes\n",
        "\n",
        "    def decode(self, codes: np.ndarray) -> np.ndarray:\n",
        "        n_samples, m = codes.shape\n",
        "        d = self.m * self.d_s\n",
        "        x_reconstructed = np.empty((n_samples, d), dtype=np.float32)\n",
        "\n",
        "        for i in range(self.m):\n",
        "            # Извлекаем векторы из книги по индексам\n",
        "            x_reconstructed[:, i * self.d_s : (i + 1) * self.d_s] = self.codebooks[i][codes[:, i]]\n",
        "\n",
        "        return x_reconstructed"
      ],
      "metadata": {
        "id": "TJx-Fb3emF-a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Часть 1**: Эксперимент на синтетических данных (Валидация)\n",
        "На этом этапе мы проводим Sanity Check (проверку корректности) нашего алгоритма. Мы генерируем искусственный набор данных, который по своему строению идеально ложится на гипотезу Product Quantization.\n",
        "\n",
        "Суть эксперимента: Данные создаются так, чтобы они уже имели скрытую структуру центроидов.\n",
        "Мы задаем размерность вектора D, количество подпространств M и количество кластеров K.\n",
        "- В каждом из M подпространств генерируются K случайных центров (идеальных значений).\n",
        "- Каждый обучающий вектор собирается как конструктор: мы берем по одному случайному центру из каждого подпространства и склеиваем их.\n",
        "- К полученному \"идеальному\" вектору добавляется Гауссовский шум.\n",
        "\n",
        "Ожидаемый результат: Если алгоритм PQ реализован верно, он должен \"проигнорировать\" добавленный шум и найти исходные центроиды. Ошибка восстановления (MSE) должна быть очень близка к дисперсии добавленного шума."
      ],
      "metadata": {
        "id": "HmuiMravwHxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Синтетические данные"
      ],
      "metadata": {
        "id": "kw_DdiHEsSom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_clustered_data(n_samples, d, m, n_clusters_per_subspace, noise_level=0.1):\n",
        "    d_s = d // m\n",
        "\n",
        "    # 1. Генерируем центры кластеров для каждого подпространства\n",
        "    true_centroids = np.random.randn(m, n_clusters_per_subspace, d_s).astype(np.float32)\n",
        "\n",
        "    data = np.empty((n_samples, d), dtype=np.float32)\n",
        "\n",
        "    perfect_data = np.empty((n_samples, d), dtype=np.float32)\n",
        "\n",
        "    for i in range(m):\n",
        "        cluster_indices = np.random.randint(0, n_clusters_per_subspace, size=n_samples)\n",
        "\n",
        "        sub_data = true_centroids[i, cluster_indices, :]\n",
        "        perfect_data[:, i*d_s : (i+1)*d_s] = sub_data\n",
        "\n",
        "        noise = np.random.randn(n_samples, d_s) * noise_level\n",
        "        data[:, i*d_s : (i+1)*d_s] = sub_data + noise\n",
        "\n",
        "    return data, perfect_data\n",
        "\n",
        "print(\"\\nЭКСПЕРИМЕНТ 1: Синтетические данные\")\n",
        "D_synth = 128\n",
        "M_synth = 8\n",
        "X_synth, X_perfect = generate_clustered_data(n_samples=5000, d=D_synth, m=M_synth, n_clusters_per_subspace=256)\n",
        "\n",
        "pq_synth = ProductQuantizer(m=M_synth, nbits=8)\n",
        "pq_synth.fit(X_synth)\n",
        "\n",
        "codes_synth = pq_synth.encode(X_synth)\n",
        "X_rec_synth = pq_synth.decode(codes_synth)\n",
        "\n",
        "mse_synth = mean_squared_error(X_synth, X_rec_synth)\n",
        "mse_noise = mean_squared_error(X_synth, X_perfect)\n",
        "\n",
        "print(f\"MSE восстановления: {mse_synth:.6f}\")\n",
        "print(f\"MSE (уровень шума): {mse_noise:.6f}\")\n",
        "print(\"Вывод: PQ должен найти центроиды, поэтому ошибка восстановления близка к уровню шума.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx-VC-BGmPxy",
        "outputId": "5571fa1b-b399-42be-9885-f652fd136d88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ЭКСПЕРИМЕНТ 1: Синтетические данные ---\n",
            "Обучение PQ: Вектор 128 dim -> 8 сегментов по 16 dim.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обучение кодовых книг: 100%|██████████| 8/8 [00:11<00:00,  1.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE восстановления: 0.009872\n",
            "MSE (уровень шума): 0.010008\n",
            "Вывод: PQ должен найти центроиды, поэтому ошибка восстановления близка к уровню шума.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Часть 2**: Реальные данные (Эмбеддинги ResNet-18)\n",
        "В этом эксперименте мы тестируем алгоритм на задаче сжатия изображений CIFAR-10. Вместо сырых пикселей используются семантические векторы (эмбеддинги) размерностью 512, полученные с выхода предобученной нейросети ResNet-18.\n",
        "\n",
        "Параметры эксперимента:\n",
        "\n",
        "Входные данные: Векторы 512 float32 (2048 байт).\n",
        "\n",
        "Настройки PQ: Разбиение вектора на 16 подпространств (M=16).\n",
        "\n",
        "Сжатие: Каждый сегмент кодируется 1 байтом. Итоговый размер кода — 16 байт.\n",
        "\n",
        "Цель: Достичь коэффициента сжатия 128x и оценить ошибку восстановления (MSE)."
      ],
      "metadata": {
        "id": "IbDNvLYyx-nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nЭКСПЕРИМЕНТ 2: Эмбеддинги (ResNet18 + CIFAR-10)\")\n",
        "def get_resnet_embeddings(n_images=2000):\n",
        "    model = torchvision.models.resnet18(weights='DEFAULT')\n",
        "\n",
        "    model.fc = torch.nn.Identity()\n",
        "    model.eval()\n",
        "\n",
        "    # Препроцессинг для ResNet\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=preprocess)\n",
        "\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size=50, shuffle=True)\n",
        "\n",
        "    embeddings_list = []\n",
        "    print(\"Генерация эмбеддингов с помощью нейросети...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(loader):\n",
        "            if i * 50 >= n_images: break\n",
        "\n",
        "            emb = model(images) # Shape: (batch, 512)\n",
        "            embeddings_list.append(emb.numpy())\n",
        "\n",
        "    return np.vstack(embeddings_list)\n",
        "\n",
        "X_emb = get_resnet_embeddings(n_images=2000)\n",
        "print(f\"Получены эмбеддинги формы: {X_emb.shape}\")\n",
        "\n",
        "# Настраиваем PQ\n",
        "M_emb = 16\n",
        "D_emb = X_emb.shape[1]\n",
        "\n",
        "if D_emb % M_emb != 0:\n",
        "    print(\"Warning: Размерность не делится на M. Обрезаем.\")\n",
        "    X_emb = X_emb[:, :(D_emb // M_emb) * M_emb]\n",
        "\n",
        "pq_emb = ProductQuantizer(m=M_emb, nbits=8)\n",
        "pq_emb.fit(X_emb)\n",
        "\n",
        "# Считаем ошибку\n",
        "codes_emb = pq_emb.encode(X_emb)\n",
        "X_rec_emb = pq_emb.decode(codes_emb)\n",
        "\n",
        "mse_emb = mean_squared_error(X_emb, X_rec_emb)\n",
        "\n",
        "# Считаем относительную ошибку\n",
        "relative_error = np.linalg.norm(X_emb - X_rec_emb) / np.linalg.norm(X_emb)\n",
        "\n",
        "print(f\"MSE на эмбеддингах: {mse_emb:.6f}\")\n",
        "print(f\"Относительная ошибка восстановления: {relative_error:.4f}\")\n",
        "\n",
        "original_size_kb = X_emb.nbytes / 1024\n",
        "compressed_size_kb = codes_emb.nbytes / 1024\n",
        "print(f\"Сжатие: {original_size_kb:.1f} KB -> {compressed_size_kb:.1f} KB (в {original_size_kb/compressed_size_kb:.1f} раз)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SONBuL1oazL",
        "outputId": "c7c1ef94-1aad-4cc3-9cbd-57fed4dc6b9b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ЭКСПЕРИМЕНТ 2: Эмбеддинги (ResNet18 + CIFAR-10) ---\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 77.6MB/s]\n",
            "100%|██████████| 170M/170M [00:04<00:00, 34.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Генерация эмбеддингов с помощью нейросети...\n",
            "Получены эмбеддинги формы: (2000, 512)\n",
            "Обучение PQ: Вектор 512 dim -> 16 сегментов по 32 dim.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обучение кодовых книг: 100%|██████████| 16/16 [00:13<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE на эмбеддингах: 0.190406\n",
            "Относительная ошибка восстановления: 0.3525\n",
            "Сжатие: 4000.0 KB -> 31.2 KB (в 128.0 раз)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yOXPV_Gjo-HA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}