{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqBIFdVjP5Sck6jASNzTA4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhtabkrklt/ML_Tasks/blob/main/product_quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ДЗ: Реализовать product quantization самостоятельно и посчитать ошибку представления на 2 датасетах:\n",
        "- сгенерированом так, чтобы в каждом под-пространстве вектора хорошо кластеризовались (центр + белый шум)\n",
        "- эмбеддингах любого датасета от любой нейронки"
      ],
      "metadata": {
        "id": "aT8UkVPguXpO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "o9w5LEcvl1DY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import mean_squared_error\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Working on device: {DEVICE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ivBZinlj8iG",
        "outputId": "c42da858-9b69-4892-ff74-0b8616696f64"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means on PyTorch for GPU"
      ],
      "metadata": {
        "id": "4MAEeFuBrAmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kmeans_pytorch(X, num_clusters, device, max_iter=50, tol=1e-4):\n",
        "    N, D = X.shape\n",
        "    indices = torch.randperm(N, device=device)[:num_clusters]\n",
        "    centroids = X[indices].clone()\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        # Считаем расстояния: (N, 1, D) - (1, K, D) -> (N, K)\n",
        "        dists = torch.cdist(X, centroids)\n",
        "\n",
        "        # Находим ближайшие центроиды\n",
        "        labels = torch.argmin(dists, dim=1)\n",
        "\n",
        "        # Пересчитываем центроиды\n",
        "        new_centroids = torch.zeros_like(centroids)\n",
        "        new_centroids.index_add_(0, labels, X)\n",
        "\n",
        "        # Считаем количество точек в каждом кластере\n",
        "        counts = torch.bincount(labels, minlength=num_clusters).float().unsqueeze(1)\n",
        "\n",
        "        # Избегаем деления на ноль\n",
        "        mask = counts > 0\n",
        "        new_centroids[mask.squeeze()] /= counts[mask.squeeze()]\n",
        "        new_centroids[~mask.squeeze()] = centroids[~mask.squeeze()]\n",
        "\n",
        "        # Проверка на сходимость\n",
        "        shift = torch.norm(new_centroids - centroids)\n",
        "        if shift < tol:\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return centroids"
      ],
      "metadata": {
        "id": "cYHKnIL6j5HY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ae8AS26Yj9ks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализация Product Quantizer"
      ],
      "metadata": {
        "id": "be83H7N1sCqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProductQuantizer:\n",
        "    def __init__(self, m: int, nbits: int = 8, device=DEVICE):\n",
        "        \"\"\"\n",
        "        m: количество подпространств (сегментов)\n",
        "        nbits: количество бит на сегмент.\n",
        "               Примечание: Обычно берется 8, чтобы индекс кластера влезал в uint8 (1 байт).\n",
        "               Выбор K - это баланс. Больше K -> меньше ошибка, но медленнее поиск и больше словарь.\n",
        "               Меньше K -> быстрее, но грубее приближение.\n",
        "        device: 'cpu' или 'cuda'\n",
        "        \"\"\"\n",
        "        self.m = m\n",
        "        self.k = 2 ** nbits\n",
        "        self.d_s = None\n",
        "        self.codebooks = None\n",
        "        self.device = device\n",
        "\n",
        "    def fit(self, x: torch.Tensor):\n",
        "\n",
        "        x = x.to(self.device)\n",
        "        n_samples, d = x.shape\n",
        "        assert d % self.m == 0, f\"Размерность {d} должна делиться на m={self.m}\"\n",
        "        self.d_s = d // self.m\n",
        "\n",
        "        # codebooks: (m, k, d_s)\n",
        "        self.codebooks = torch.empty((self.m, self.k, self.d_s), device=self.device)\n",
        "\n",
        "        print(f\"Обучение PQ на {self.device}: Вектор {d} dim -> {self.m} сегментов по {self.d_s} dim.\")\n",
        "\n",
        "        for i in tqdm.tqdm(range(self.m), desc=\"Обучение подпространств\"):\n",
        "            x_sub = x[:, i * self.d_s : (i + 1) * self.d_s]\n",
        "\n",
        "            centroids = kmeans_pytorch(x_sub, self.k, device=self.device)\n",
        "            self.codebooks[i] = centroids\n",
        "\n",
        "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Кодирование векторов. Возвращает индексы (коды).\n",
        "        \"\"\"\n",
        "        x = x.to(self.device)\n",
        "        n_samples, d = x.shape\n",
        "        codes = torch.empty((n_samples, self.m), dtype=torch.long, device=self.device)\n",
        "\n",
        "        for i in range(self.m):\n",
        "            x_sub = x[:, i * self.d_s : (i + 1) * self.d_s]\n",
        "            codebook = self.codebooks[i]\n",
        "\n",
        "            # Расстояния ||x - c||\n",
        "            dists = torch.cdist(x_sub, codebook) # (N, K)\n",
        "\n",
        "            codes[:, i] = torch.argmin(dists, dim=1)\n",
        "\n",
        "        return codes\n",
        "\n",
        "    def decode(self, codes: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Восстановление векторов по кодам.\n",
        "        \"\"\"\n",
        "        codes = codes.to(self.device)\n",
        "        n_samples, m = codes.shape\n",
        "        d = self.m * self.d_s\n",
        "        x_reconstructed = torch.empty((n_samples, d), device=self.device)\n",
        "\n",
        "        for i in range(self.m):\n",
        "            # codes[:, i] - это индексы центроидов для i-го сегмента\n",
        "            x_reconstructed[:, i * self.d_s : (i + 1) * self.d_s] = self.codebooks[i][codes[:, i]]\n",
        "\n",
        "        return x_reconstructed"
      ],
      "metadata": {
        "id": "TJx-Fb3emF-a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Часть 1:** **Эксперимент на синтетических данных**\n",
        "\n",
        "На этом этапе мы проверяем корректность нашей реализации Product Quantization на PyTorch. Мы генерируем искусственный набор данных с заранее известной структурой, чтобы убедиться, что алгоритм работает верно.\n",
        "\n",
        "Суть эксперимента:\n",
        "\n",
        "Унификация: Мы используем размерность вектора D=512 (как у ResNet в следующем эксперименте), чтобы проверить работу на реалистичных объемах.\n",
        "\n",
        "Генерация: Данные создаются из идеальных центроидов, к которым добавляется Гауссовский шум.\n",
        "\n",
        "Технологии: Вычисления производятся на GPU (CUDA) для проверки скорости и корректности тензорных операций.\n",
        "\n",
        "Ожидаемый результат:\n",
        "\n",
        "MSE восстановления должна быть очень близка к дисперсии добавленного шума (PQ находит \"истинные\" центры, игнорируя шум).\n",
        "\n",
        "Cosine Similarity должна стремиться к 1 (показывая, что направление векторов сохранено)."
      ],
      "metadata": {
        "id": "HmuiMravwHxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Синтетические данные"
      ],
      "metadata": {
        "id": "kw_DdiHEsSom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_clustered_data(n_samples, d, m, n_clusters_per_subspace, noise_level=0.1):\n",
        "    d_s = d // m\n",
        "    true_centroids = torch.randn(m, n_clusters_per_subspace, d_s)\n",
        "\n",
        "    data = torch.empty((n_samples, d))\n",
        "    perfect_data = torch.empty((n_samples, d))\n",
        "\n",
        "    for i in range(m):\n",
        "        cluster_indices = torch.randint(0, n_clusters_per_subspace, (n_samples,))\n",
        "        sub_data = true_centroids[i][cluster_indices]\n",
        "        perfect_data[:, i*d_s : (i+1)*d_s] = sub_data\n",
        "\n",
        "        noise = torch.randn(n_samples, d_s) * noise_level\n",
        "        data[:, i*d_s : (i+1)*d_s] = sub_data + noise\n",
        "\n",
        "    return data, perfect_data"
      ],
      "metadata": {
        "id": "Yx-VC-BGmPxy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_compression(X_orig, X_rec, codes, name=\"Experiment\"):\n",
        "    X_orig = X_orig.to(DEVICE)\n",
        "    X_rec = X_rec.to(DEVICE)\n",
        "\n",
        "    # 1. MSE\n",
        "    mse = torch.nn.functional.mse_loss(X_orig, X_rec).item()\n",
        "\n",
        "    # 2. Cosine Similarity\n",
        "    cos_sim = torch.nn.functional.cosine_similarity(X_orig, X_rec).mean().item()\n",
        "\n",
        "    # 3. Коэффициент сжатия\n",
        "    orig_bytes = X_orig.element_size() * X_orig.nelement()\n",
        "    comp_bytes = codes.element_size() * codes.nelement()\n",
        "    ratio = orig_bytes / comp_bytes\n",
        "\n",
        "    print(f\"\\nРЕЗУЛЬТАТЫ: {name}\")\n",
        "    print(f\"{'-'*40}\")\n",
        "    print(f\"MSE :      {mse:.6f}\")\n",
        "    print(f\"Cosine Similarity (Качество):  {cos_sim:.4f} (1.0 = идеал)\")\n",
        "    print(f\"Сжатие (Эффективность):        {orig_bytes/1024:.1f} KB -> {comp_bytes/1024:.1f} KB (в {ratio:.1f} раз)\")\n",
        "    print(f\"{'-'*40}\")\n",
        "\n",
        "    return mse, cos_sim"
      ],
      "metadata": {
        "id": "L1NVJwtkloK9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nЭКСПЕРИМЕНТ 1: Синтетические данные\")\n",
        "D_COMMON = 512\n",
        "M_COMMON = 16\n",
        "NBITS = 8\n",
        "\n",
        "X_synth, X_perfect = generate_clustered_data(n_samples=5000, d=D_COMMON, m=M_COMMON, n_clusters_per_subspace=256)\n",
        "\n",
        "pq_synth = ProductQuantizer(m=M_COMMON, nbits=NBITS, device=DEVICE)\n",
        "pq_synth.fit(X_synth)\n",
        "\n",
        "codes_synth = pq_synth.encode(X_synth)\n",
        "X_rec_synth = pq_synth.decode(codes_synth)\n",
        "\n",
        "evaluate_compression(X_synth, X_rec_synth, codes_synth, name=\"Синтетика (Шумные данные)\")\n",
        "evaluate_compression(X_perfect, X_rec_synth, codes_synth, name=\"Синтетика (Проверка против Идеала)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tngXR-iwluSZ",
        "outputId": "2e7423ea-c19e-4b29-e263-fcb2b184989f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ЭКСПЕРИМЕНТ 1: Синтетические данные\n",
            "Обучение PQ на cuda: Вектор 512 dim -> 16 сегментов по 32 dim.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обучение подпространств: 100%|██████████| 16/16 [00:00<00:00, 171.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "РЕЗУЛЬТАТЫ: Синтетика (Шумные данные)\n",
            "----------------------------------------\n",
            "MSE :      0.148720\n",
            "Cosine Similarity (Качество):  0.9235 (1.0 = идеал)\n",
            "Сжатие (Эффективность):        10000.0 KB -> 625.0 KB (в 16.0 раз)\n",
            "----------------------------------------\n",
            "\n",
            "РЕЗУЛЬТАТЫ: Синтетика (Проверка против Идеала)\n",
            "----------------------------------------\n",
            "MSE :      0.139925\n",
            "Cosine Similarity (Качество):  0.9274 (1.0 = идеал)\n",
            "Сжатие (Эффективность):        10000.0 KB -> 625.0 KB (в 16.0 раз)\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.13992474973201752, 0.9274211525917053)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Высокое качество восстановления: Косинусная близость ~0.92-0.93 говорит о том, что алгоритм успешно нашел структуру данных и сохранил направление векторов практически без искажений.\n",
        "\n",
        "Эффективность: Достигнуто сжатие в 16 раз (с 10 МБ до 625 КБ) при сохранении высокой точности.\n",
        "\n",
        "Корректность работы: Низкая ошибка MSE (~0.14) и высокая схожесть с идеальными центроидами подтверждают, что ваша реализация Product Quantization работает верно и устойчива к шуму"
      ],
      "metadata": {
        "id": "y5193LrYtUa7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Часть 2: Реальные данные (Эмбеддинги ResNet-18)**\n",
        "\n",
        "В этом эксперименте мы тестируем алгоритм на реальной задаче сжатия семантических векторов изображений из датасета CIFAR-10. Мы используем эмбеддинги размерностью 512, полученные с выхода нейросети ResNet-18.\n",
        "\n",
        "Параметры эксперимента:\n",
        "\n",
        "Входные данные: Векторы размерностью 512 (float32), занимающие 2048 байт.\n",
        "\n",
        "Настройки PQ: Вектор разбивается на 16 подпространств (M=16), каждое кодируется 8 битами (nbits=8).\n",
        "\n",
        "Сжатие: Итоговый код занимает всего 16 байт (против исходных 2048). Коэффициент сжатия — 128x."
      ],
      "metadata": {
        "id": "IbDNvLYyx-nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nЭКСПЕРИМЕНТ 2: Эмбеддинги (ResNet18)\")\n",
        "def get_resnet_embeddings(n_images=2000):\n",
        "    model = torchvision.models.resnet18(weights='DEFAULT')\n",
        "    model.fc = torch.nn.Identity()\n",
        "    model.eval()\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=preprocess)\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
        "\n",
        "    embeddings_list = []\n",
        "    print(\"Генерация эмбеддингов...\")\n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(loader):\n",
        "            if i * 100 >= n_images: break\n",
        "            images = images.to(DEVICE)\n",
        "            emb = model(images)\n",
        "            embeddings_list.append(emb.cpu())\n",
        "\n",
        "    return torch.vstack(embeddings_list)\n",
        "\n",
        "X_emb = get_resnet_embeddings(n_images=2000)\n",
        "\n",
        "pq_emb = ProductQuantizer(m=M_COMMON, nbits=NBITS, device=DEVICE)\n",
        "pq_emb.fit(X_emb)\n",
        "\n",
        "codes_emb = pq_emb.encode(X_emb)\n",
        "X_rec_emb = pq_emb.decode(codes_emb)\n",
        "\n",
        "evaluate_compression(X_emb, X_rec_emb, codes_emb, name=\"Эмбеддинги ResNet18\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SONBuL1oazL",
        "outputId": "aed3e05b-d0f6-4ca8-c95c-6d9f4ca376a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ЭКСПЕРИМЕНТ 2: Эмбеддинги (ResNet18)\n",
            "Генерация эмбеддингов...\n",
            "Обучение PQ на cuda: Вектор 512 dim -> 16 сегментов по 32 dim.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обучение подпространств: 100%|██████████| 16/16 [00:00<00:00, 112.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "РЕЗУЛЬТАТЫ: Эмбеддинги ResNet18\n",
            "----------------------------------------\n",
            "MSE :      0.197093\n",
            "Cosine Similarity (Качество):  0.9329 (1.0 = идеал)\n",
            "Сжатие (Эффективность):        4000.0 KB -> 250.0 KB (в 16.0 раз)\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.19709299504756927, 0.932908296585083)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Высокое качество: Косинусная близость 0.9329 означает, что сжатые векторы сохранили более 93% семантического смысла. Это отличный результат для задач поиска (Retrieval) и рекомендаций.\n",
        "\n",
        "Эффективность сжатия: Объем данных уменьшен в 16 раз (с 4 МБ до 250 КБ), что существенно экономит память.\n",
        "\n",
        "Производительность: Использование GPU (CUDA) обеспечило высокую скорость обучения."
      ],
      "metadata": {
        "id": "-BGdxPB0tlWM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yOXPV_Gjo-HA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}